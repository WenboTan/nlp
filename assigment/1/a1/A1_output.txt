================================================================================
A1 ASSIGNMENT - FINAL RESULTS
================================================================================

TRAINING CONFIGURATION
--------------------------------------------------------------------------------
Model Architecture: LSTM-based Language Model
  - Embedding size: 256
  - Hidden size: 512
  - Vocabulary size: 20,000
  - Max sequence length: 128

Training Setup:
  - Optimizer: AdamW
  - Learning rate: 5e-4
  - Batch size: 64
  - Number of epochs: 3
  - Hardware: NVIDIA L4 GPU
  - PyTorch version: 2.5.1 + CUDA 12.1

Training Progress:
  Epoch 1/3: Train loss 5.692, Val loss 5.223
  Epoch 2/3: Train loss 5.063, Val loss 4.915
  Epoch 3/3: Train loss 4.777, Val loss 4.753

================================================================================
VALIDATION SET PERPLEXITY (REQUIRED OUTPUT)
================================================================================

Validation Loss (per token): 4.753313
Validation Perplexity: 115.9679

The model achieves a perplexity of approximately 116 on the validation set,
indicating reasonable language modeling performance. The perplexity decreased
from 184.7 (epoch 1) to 115.97 (epoch 3), showing continued improvement.

================================================================================
NEXT-WORD PREDICTIONS (REQUIRED OUTPUT)
================================================================================

Test Prompt 1: "The president of the"
Top 5 predictions:
  1. was                  (probability: 0.1298)
  2. is                   (probability: 0.1108)
  3. ,                    (probability: 0.0481)
  4. and                  (probability: 0.0224)
  5. has                  (probability: 0.0222)

Test Prompt 2: "In the year"
Top 5 predictions:
  1. ,                    (probability: 0.1480)
  2. <UNK>                (probability: 0.1019)
  3. the                  (probability: 0.0684)
  4. "                    (probability: 0.0456)
  5. and                  (probability: 0.0115)

Test Prompt 3: "The capital of"
Top 5 predictions:
  1. is                   (probability: 0.0836)
  2. was                  (probability: 0.0662)
  3. <UNK>                (probability: 0.0438)
  4. ,                    (probability: 0.0416)
  5. <EOS>                (probability: 0.0409)

Test Prompt 4: "Scientists have discovered"
Top 5 predictions:
  1. <UNK>                (probability: 0.1299)
  2. ,                    (probability: 0.0422)
  3. and                  (probability: 0.0321)
  4. to                   (probability: 0.0287)
  5. for                  (probability: 0.0249)

Test Prompt 5: "The most important thing is"
Top 5 predictions:
  1. ,                    (probability: 0.2312)
  2. to                   (probability: 0.0700)
  3. <UNK>                (probability: 0.0616)
  4. and                  (probability: 0.0584)
  5. (                    (probability: 0.0565)

================================================================================
OBSERVATIONS
================================================================================

The model shows reasonable next-word prediction capabilities:
- Correctly predicts grammatical continuations (e.g., "is", "was" after nouns)
- Handles common phrases appropriately
- Shows uncertainty with <UNK> tokens when context is ambiguous
- Predicts punctuation when grammatically appropriate

Training completed successfully on NVIDIA L4 GPU.
Total training time: approximately 13 minutes for 3 epochs.

================================================================================
END OF OUTPUT
================================================================================

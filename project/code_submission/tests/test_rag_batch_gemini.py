"""
Batch test script - Google Geminiversion
For testing in SLURM jobs Gemini RAG system
No interactive input required, runs predefined test queries
"""

import os
from pathlib import Path
from dotenv import load_dotenv

from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from langchain_core.output_parsers import StrOutputParser


# Configuration
DB_PATH = './chalmers_chroma_db'
EMBEDDING_MODEL = 'sentence-transformers/all-MiniLM-L6-v2'
GEMINI_MODEL = "gemini-2.5-flash"  # ä½¿ç”¨å¿«é€Ÿversionè¿›è¡Œæµ‹è¯•
RETRIEVAL_K = 10  # å¢åŠ æ£€ç´¢æ•°é‡ä»¥æé«˜è¦†ç›–ç‡

# æµ‹è¯•æŸ¥è¯¢åˆ—è¡¨ï¼ˆè¦†ç›–å¤šç§æŸ¥è¯¢åœºæ™¯ï¼‰
TEST_QUERIES = [
    # 1. è¯¾ç¨‹æœç´¢ - æŒ‰ä¸»é¢˜
    "What machine learning courses are available?",
    
    # 2. é¢†åŸŸæŸ¥è¯¢
    "Tell me about database courses at Chalmers.",
    
    # 3. æ—¶é—´å†²çªæ£€æµ‹ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰
    "Can I take TDA357 and DAT450 together? Do they have schedule conflicts?",
    
    # 4. å…ˆä¿®è¯¾ç¨‹æŸ¥è¯¢
    "What are the prerequisites for advanced programming courses?",
    
    # 5. æŒ‰Blockå’Œå­¦åˆ†ç­›é€‰
    "Show me all 7.5 credit courses offered in Block C.",
    
    # 6. è¯­è¨€è¦æ±‚æŸ¥è¯¢
    "Which courses are taught in English and suitable for international students?",
    
    # 7. å…·ä½“è¯¾ç¨‹è¯¦æƒ…
    "Tell me everything about the course TDA357.",
    
    # 8. è¯¾ç¨‹æ¯”è¾ƒ
    "What's the difference between DAT450 and TDA362?",
    
    # 9. é¡¹ç›®å‹è¯¾ç¨‹
    "Are there any courses that involve working on real projects?",
    
    # 10. æ¨èè¯¾ç¨‹ï¼ˆç»¼åˆæŸ¥è¯¢ï¼‰
    "I'm interested in AI and want to take courses in spring (Block 3 and 4). What do you recommend?"
]


def load_vector_store(db_path: str = DB_PATH) -> Chroma:
    """Load vector database"""
    print(f"Loading vector database from {db_path}...")
    
    if not Path(db_path).exists():
        raise FileNotFoundError(
            f"Vector database not found at {db_path}.\n"
            "Please run: python build_vector_db.py"
        )
    
    embeddings = HuggingFaceEmbeddings(
        model_name=EMBEDDING_MODEL,
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )
    
    vectorstore = Chroma(
        persist_directory=db_path,
        embedding_function=embeddings,
        collection_name='chalmers_courses'
    )
    
    print(f"âœ“ Vector store loaded")
    return vectorstore


def load_gemini_llm(model: str = GEMINI_MODEL) -> ChatGoogleGenerativeAI:
    """åŠ è½½ Google Gemini LLM"""
    load_dotenv()
    
    api_key = os.getenv('GOOGLE_API_KEY')
    if not api_key:
        raise ValueError(
            "\nâŒ GOOGLE_API_KEY not found!\n"
            "Please set it in .env file or as environment variable.\n"
            "Get your API key at: https://makersuite.google.com/app/apikey"
        )
    
    print(f"\n{'='*70}")
    print(f"Loading Google Gemini: {model}")
    print(f"API Key: {api_key[:10]}...{api_key[-4:]}")
    print(f"{'='*70}\n")
    
    llm = ChatGoogleGenerativeAI(
        model=model,
        temperature=0.3,
        google_api_key=api_key,
        convert_system_message_to_human=True
    )
    
    return llm


def create_rag_prompt() -> ChatPromptTemplate:
    """Create RAG prompt template"""
    system_message = """You are a helpful Chalmers University Course Assistant. 
Your job is to answer questions about courses using the provided context.

IMPORTANT INSTRUCTIONS:

1. **Use Only Retrieved Context**: Base your answers strictly on the context provided below. 
   If you cannot find the answer in the context, say "I don't have enough information about that in the course database."

2. **Schedule Conflict Detection**: 
   - When a user asks if they can take multiple courses together (e.g., "Can I take course A and B?"), 
     CHECK THE "Schedule Block" field in the context.
   - If two courses have the **same Block** (e.g., both are "Block C"), they have a TIME CONFLICT.
   - Example: Block "C" conflicts with "C", Block "D" conflicts with "D"
   - If blocks are different, courses do NOT conflict.
   
3. **Include Key Information**:
   - Always mention the course code when discussing a course
   - Include the course URL if available
   - Mention prerequisites, credits, language when relevant

4. **Be Concise and Clear**:
   - Use bullet points for multiple courses
   - Highlight important information like conflicts or prerequisites
   - Provide direct, actionable answers

Context from course database:
{context}

Question: {question}

Answer:"""
    
    return ChatPromptTemplate.from_template(system_message)


def format_docs(docs) -> str:
    """Format retrieved documents as context string"""
    formatted = []
    for i, doc in enumerate(docs, 1):
        formatted.append(f"--- Document {i} ---")
        formatted.append(f"Course Code: {doc.metadata.get('course_code', 'Unknown')}")
        formatted.append(f"Schedule Block: {doc.metadata.get('block', 'Unknown')}")
        formatted.append(f"Credits: {doc.metadata.get('credits', 'Unknown')}")
        formatted.append(f"URL: {doc.metadata.get('url', 'N/A')}")
        formatted.append(f"\n{doc.page_content}\n")
    return "\n".join(formatted)


def create_rag_chain(vectorstore: Chroma, llm, k: int = RETRIEVAL_K):
    """Create RAG chain (using LCEL)- ä½¿ç”¨smart retriever"""
    import re
    
    def smart_retriever(question: str):
        """æ™ºèƒ½Retrieverï¼šæå–è¯¾ç¨‹ä»£ç å¹¶è¿›è¡Œé’ˆå¯¹æ€§æ£€ç´¢"""
        # æå–å¯èƒ½çš„è¯¾ç¨‹ä»£ç  (å¦‚ TDA357, DAT450)
        course_codes = re.findall(r'\b[A-Z]{3}\d{3}\b', question.upper())
        
        all_docs = []
        
        # å¦‚æœæåˆ°äº†ç‰¹å®šè¯¾ç¨‹ä»£ç ï¼Œä½¿ç”¨metadata filterç²¾ç¡®æ£€ç´¢
        if course_codes:
            for code in course_codes:
                try:
                    # ä½¿ç”¨metadata filterç²¾ç¡®æŸ¥æ‰¾è¯¾ç¨‹
                    code_docs = vectorstore.similarity_search(
                        question,  # ä½¿ç”¨åŸå§‹é—®é¢˜ä»¥ä¿æŒç›¸å…³æ€§
                        k=5,  # æ¯ä¸ªè¯¾ç¨‹è·å–5ä¸ªchunks
                        filter={'course_code': code}
                    )
                    all_docs.extend(code_docs)
                except Exception as e:
                    pass  # é™é»˜å¤±è´¥ï¼Œåœ¨æµ‹è¯•ä¸­
        
        # å¦‚æœæ²¡æ‰¾åˆ°è¶³å¤Ÿæ–‡æ¡£ï¼Œæˆ–è€…æ²¡æœ‰è¯¾ç¨‹ä»£ç ï¼Œä½¿ç”¨æ›´å¤§çš„Kå€¼è¿›è¡Œè¯­ä¹‰æ£€ç´¢
        if len(all_docs) < 5:
            semantic_docs = vectorstore.similarity_search(question, k=k*2)  # Kå€¼ç¿»å€
            # åˆå¹¶å¹¶å»é‡
            for doc in semantic_docs:
                if doc not in all_docs:
                    all_docs.append(doc)
        
        # è¿”å›æœ€å¤šk*2ä¸ªæ–‡æ¡£
        return all_docs[:k*2]
    
    prompt = create_rag_prompt()
    
    rag_chain = (
        {
            'context': RunnableLambda(smart_retriever) | format_docs,
            'question': RunnablePassthrough()
        }
        | prompt
        | llm
        | StrOutputParser()
    )
    
    return rag_chain


def run_batch_test(rag_chain, queries: list):
    """è¿è¡Œæ‰¹é‡æµ‹è¯•"""
    print("\n" + "=" * 70)
    print(f"Running batch test with {len(queries)} queries")
    print("=" * 70 + "\n")
    
    results = []
    
    for i, query in enumerate(queries, 1):
        print("=" * 70)
        print(f"Test Query {i}/{len(queries)}")
        print("=" * 70)
        print(f"Question: {query}\n")
        
        try:
            print("Generating answer...")
            answer = rag_chain.invoke(query)
            
            print("\nğŸ¤– Answer:\n")
            print(answer)
            print("\n")
            
            results.append({
                'query': query,
                'answer': answer,
                'status': 'success'
            })
            
        except Exception as e:
            print(f"\nâŒ Error: {e}\n")
            results.append({
                'query': query,
                'error': str(e),
                'status': 'failed'
            })
    
    # æ‰“å°æ€»ç»“
    print("\n" + "=" * 70)
    print("âœ… All tests completed!")
    print("=" * 70)
    
    success_count = sum(1 for r in results if r['status'] == 'success')
    print(f"\nResults: {success_count}/{len(queries)} successful")
    
    return results


def main():
    """Main function"""
    print("\n" + "="*70)
    print("Chalmers Course RAG System - Batch Test Mode")
    print("="*70)
    
    try:
        # Step 1: Load vector database
        print("\n" + "="*70)
        print("Step 1: Loading Vector Database")
        print("="*70)
        vectorstore = load_vector_store()
        
        # Step 2: Initialize Gemini LLM
        print("\n" + "="*70)
        print("Step 2: Initializing Google Gemini LLM")
        print("="*70)
        llm = load_gemini_llm()
        print("âœ“ LLM ready")
        
        # Step 3: Build RAG chain
        print("\n" + "="*70)
        print("Step 3: Building RAG Chain")
        print("="*70)
        rag_chain = create_rag_chain(vectorstore, llm)
        print("âœ“ RAG chain ready")
        
        # Step 4: è¿è¡Œæ‰¹é‡æµ‹è¯•
        results = run_batch_test(rag_chain, TEST_QUERIES)
        
        return 0
        
    except Exception as e:
        print(f"\nâŒ Fatal Error: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    exit(main())

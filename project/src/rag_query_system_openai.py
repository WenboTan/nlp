"""
OpenAI API ç‰ˆæœ¬çš„ RAG é—®ç­”ç³»ç»Ÿ
ä½¿ç”¨ OpenAI GPT æ¨¡å‹ï¼Œéœ€è¦ API Key

ä¼˜ç‚¹ï¼š
- å›ç­”è´¨é‡æœ€é«˜
- æ¨ç†èƒ½åŠ›å¼º
- å¯åŠ¨é€Ÿåº¦å¿«ï¼ˆæ— éœ€åŠ è½½æ¨¡å‹ï¼‰

ç¼ºç‚¹ï¼š
- éœ€è¦ä»˜è´¹ï¼ˆçº¦ $0.01-0.04 æ¯æ¬¡æŸ¥è¯¢ï¼‰
- éœ€è¦ç½‘ç»œè¿æ¥
"""

import os
from pathlib import Path
from dotenv import load_dotenv

from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser


# ===== é…ç½® =====
DB_PATH = './chalmers_chroma_db'
EMBEDDING_MODEL = 'sentence-transformers/all-MiniLM-L6-v2'

# OpenAI æ¨¡å‹é€‰æ‹©
OPENAI_MODEL = "gpt-4o-mini"  # æ¨èï¼šæ€§ä»·æ¯”æœ€é«˜ï¼ˆ$0.15/$0.60 per 1M tokensï¼‰
# OPENAI_MODEL = "gpt-3.5-turbo"  # ä¾¿å®œä½†è´¨é‡ç¨å·®ï¼ˆ$0.50/$1.50 per 1M tokensï¼‰
# OPENAI_MODEL = "gpt-4o"         # æœ€å¥½ä½†è¾ƒè´µï¼ˆ$2.50/$10.00 per 1M tokensï¼‰

RETRIEVAL_K = 5


def load_vector_store(db_path: str = DB_PATH) -> Chroma:
    """åŠ è½½å‘é‡æ•°æ®åº“"""
    print(f"Loading vector database from {db_path}...")
    
    if not Path(db_path).exists():
        raise FileNotFoundError(
            f"Vector database not found at {db_path}.\n"
            "Please run: python build_vector_db.py"
        )
    
    embeddings = HuggingFaceEmbeddings(
        model_name=EMBEDDING_MODEL,
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )
    
    vectorstore = Chroma(
        persist_directory=db_path,
        embedding_function=embeddings,
        collection_name='chalmers_courses'
    )
    
    print(f"âœ“ Vector store loaded")
    return vectorstore


def load_openai_llm(model: str = OPENAI_MODEL) -> ChatOpenAI:
    """
    åŠ è½½ OpenAI LLM
    
    éœ€è¦è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY
    æˆ–åœ¨ .env æ–‡ä»¶ä¸­é…ç½®
    """
    # åŠ è½½ .env æ–‡ä»¶
    load_dotenv()
    
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        raise ValueError(
            "\nâŒ OPENAI_API_KEY not found!\n\n"
            "Please set your OpenAI API key:\n"
            "  1. Create .env file: cp .env.example .env\n"
            "  2. Edit .env and add: OPENAI_API_KEY=sk-your-key-here\n"
            "  3. Or set environment variable: export OPENAI_API_KEY=sk-your-key-here\n\n"
            "Get your API key at: https://platform.openai.com/api-keys"
        )
    
    print(f"\n{'='*70}")
    print(f"Using OpenAI Model: {model}")
    print(f"API Key: {api_key[:10]}...{api_key[-4:]}")
    print(f"{'='*70}\n")
    
    llm = ChatOpenAI(
        model=model,
        temperature=0.3,  # ä½æ¸©åº¦ = æ›´äº‹å®æ€§çš„å›ç­”
        api_key=api_key
    )
    
    return llm


def create_rag_prompt() -> ChatPromptTemplate:
    """
    åˆ›å»º RAG Prompt æ¨¡æ¿
    é’ˆå¯¹è¯¾ç¨‹åŠ©æ‰‹ä¼˜åŒ–
    """
    system_message = """You are a helpful Chalmers University Course Assistant. 
Your job is to answer questions about courses using the provided context.

IMPORTANT INSTRUCTIONS:

1. **Use Only Retrieved Context**: Base your answers strictly on the context provided below. 
   If you cannot find the answer in the context, say "I don't have enough information about that in the course database."

2. **Schedule Conflict Detection**: 
   - When a user asks if they can take multiple courses together (e.g., "Can I take course A and B?"), 
     CHECK THE "Schedule Block" field in the context.
   - If two courses have the **same Block** (e.g., both are "Block C"), they have a TIME CONFLICT.
   - Example: Block "C" conflicts with "C", Block "D" conflicts with "D"
   - If blocks are different, courses do NOT conflict.
   
3. **Include Key Information**:
   - Always mention the course code when discussing a course
   - Include the course URL if available
   - Mention prerequisites, credits, language when relevant

4. **Be Concise and Clear**:
   - Use bullet points for multiple courses
   - Highlight important information like conflicts or prerequisites
   - Provide direct, actionable answers

Context from course database:
{context}

Question: {question}

Answer:"""
    
    return ChatPromptTemplate.from_template(system_message)


def format_docs(docs) -> str:
    """æ ¼å¼åŒ–æ£€ç´¢åˆ°çš„æ–‡æ¡£ä¸ºä¸Šä¸‹æ–‡å­—ç¬¦ä¸²"""
    formatted = []
    for i, doc in enumerate(docs, 1):
        formatted.append(f"--- Document {i} ---")
        formatted.append(f"Course Code: {doc.metadata.get('course_code', 'Unknown')}")
        formatted.append(f"Schedule Block: {doc.metadata.get('block', 'Unknown')}")
        formatted.append(f"Credits: {doc.metadata.get('credits', 'Unknown')}")
        formatted.append(f"URL: {doc.metadata.get('url', 'N/A')}")
        formatted.append(f"\n{doc.page_content}\n")
    return "\n".join(formatted)


def create_rag_chain(vectorstore: Chroma, llm, k: int = RETRIEVAL_K):
    """
    åˆ›å»º RAG é“¾ï¼ˆä½¿ç”¨ LCELï¼‰
    
    Args:
        vectorstore: Chroma å‘é‡æ•°æ®åº“
        llm: è¯­è¨€æ¨¡å‹
        k: æ£€ç´¢çš„æ–‡æ¡£æ•°é‡
    
    Returns:
        å¯æ‰§è¡Œçš„ RAG é“¾
    """
    # åˆ›å»ºæ£€ç´¢å™¨
    retriever = vectorstore.as_retriever(
        search_type='similarity',
        search_kwargs={'k': k}
    )
    
    # åˆ›å»º prompt
    prompt = create_rag_prompt()
    
    # æ„å»ºé“¾: Retrieve -> Format -> Prompt -> LLM -> Parse
    rag_chain = (
        {
            'context': retriever | format_docs,
            'question': RunnablePassthrough()
        }
        | prompt
        | llm
        | StrOutputParser()
    )
    
    return rag_chain


def interactive_query_loop(rag_chain):
    """äº¤äº’å¼é—®ç­”å¾ªç¯"""
    print("\n" + "=" * 70)
    print("ğŸ“ Chalmers Course Assistant - OpenAI Mode")
    print("=" * 70)
    print("\nAsk me anything about Chalmers courses!")
    print("\nExamples:")
    print("  - What machine learning courses are available?")
    print("  - Can I take TDA357 and DAT450 together?")
    print("  - Tell me about courses in block C")
    print("  - What are the prerequisites for database courses?")
    print("  - Which courses are open for exchange students?")
    print("\nType 'quit', 'exit', or 'q' to stop.")
    print("=" * 70 + "\n")
    
    query_count = 0
    
    while True:
        try:
            # è·å–ç”¨æˆ·è¾“å…¥
            question = input("\nğŸ’¬ You: ").strip()
            
            # æ£€æŸ¥é€€å‡ºå‘½ä»¤
            if question.lower() in ['quit', 'exit', 'q', 'bye']:
                print(f"\nğŸ‘‹ Goodbye! Answered {query_count} questions.")
                break
            
            # è·³è¿‡ç©ºè¾“å…¥
            if not question:
                continue
            
            # ç”Ÿæˆç­”æ¡ˆ
            print("\nğŸ¤– Assistant: ", end="", flush=True)
            answer = rag_chain.invoke(question)
            print(answer)
            
            query_count += 1
            
        except KeyboardInterrupt:
            print(f"\n\nğŸ‘‹ Interrupted. Answered {query_count} questions.")
            break
        except Exception as e:
            print(f"\nâŒ Error: {e}")
            print("Please try again or type 'quit' to exit.")


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*70)
    print("Chalmers Course RAG System - OpenAI Version")
    print("="*70)
    
    try:
        # Step 1: åŠ è½½å‘é‡æ•°æ®åº“
        print("\n" + "="*70)
        print("Step 1: Loading Vector Database")
        print("="*70)
        vectorstore = load_vector_store()
        
        # Step 2: åˆå§‹åŒ– OpenAI LLM
        print("\n" + "="*70)
        print("Step 2: Initializing OpenAI LLM")
        print("="*70)
        llm = load_openai_llm()
        print("âœ“ LLM ready")
        
        # Step 3: æ„å»º RAG é“¾
        print("\n" + "="*70)
        print("Step 3: Building RAG Chain")
        print("="*70)
        rag_chain = create_rag_chain(vectorstore, llm)
        print("âœ“ RAG chain ready")
        
        # Step 4: è¿›å…¥äº¤äº’æ¨¡å¼
        interactive_query_loop(rag_chain)
        
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == '__main__':
    exit(main())
